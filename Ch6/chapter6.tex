%!TEX root = ../thesis.tex
\chapter{Coregistration of High Resolution Rat Histology}
% If you like chapter abstracts ...
\dblspace
\begin{quote}{\em \input{Ch6/abstract6}}\end{quote}

CONFIRMATION REPORT
\section{Aims} % (fold)
\label{sec:aims}

  MOTIVATION, PROBLEMS, AIMS
  
  Having shown in an idealised geometry that fibre direction could have a significant effect on propagation, the challenge is set to characterise cardiac tissue at sufficient detail to resolve both fibre direction and other microstructure. Cell type distribution, the shape of tissue boundaries, the Purkinje fibre network, sheet structure and vasculature all affect macroscopic wave propagation. In this section we will lay the foundations for investigating these effects by registering high-resolution histological data with MRI images. Following on from the work touched on in section~\ref{sec:cardiac_tissue_can_be_accurately_characterised_with_high_resolution_data} by \cite{Mansoori2007}, we will first examine more closely the sources of deformation introduced by the image acquisition process. A brief summary of computational tools will follow, before an overview of the registration method. We end with a discussion of the progress so far and some thoughts on what the finished pipeline will yield.
  
  
  
  Intro/Motivation
  People have tried to align block faces, but can't use certain dyes, transmission problems, lo res with Lo res data.
  People have tried to align hires stuff, but we know that this is not consistent.
  ASK VICENTE FOR REFS. MARK BOYETT FIRST AUTHOR OF ONE PAPER. ASK BECKY FOR INTRO/METHODS PAPERS.
  First attempt to use both sets of data to make coherent hires dyed segmented etc.
  
  \emph{This paper will be composed of four main sections: an overview of experimental methods, a review of the architecture of the library developed to register the raw data, a comparison of algorithms and their utility to this end, and finally the results of successful registration, with several colour figures providing visual validation of the methods.}
  
  The aim of this chapter is to develop an automated pipeline to register high resolution rat cardiac datasets robustly and accurately, and generate coherent subcellular resolution 3-D cardiac histological images.  Approximately three full rat heart datasets will be processed through the pipeline to provide registered volumes. These images will serve both as an authoritative anatomical reference, and as the basis for anatomically based models in simulation studies.
  
% section aims (end)

\section{Methods} % (fold)
\label{sec:methods}
  INTRODUCTORY PARAGRAPH
  
  \subsection{Image Acquisition} % (fold)
  \label{sub:image_acquisition}
    Hearts were isolated from female rats and cannulated via the aorta to a Langendorff perfusion system, in a similar manner to that presented in \cite{Burton2006}. The hearts were then fixed and stabilised in agar, and 26.4 x 26.4 x 26.4$\mu$m MRI scans were performed. The hearts were immersed in increasing concentrations of alcohol, in order to dehydrate them before embedding them in black wax. The wax blocks were then serially sectioned at 10$\mu$m thickness using a microtome. An image of the top surface of the block was taken with 25$\mu$m resolution after each slicing. Every 5th section was Trichrome stained, labelling connective tissue bluish-green, myocytes pinkish-red and nuclei blue-black. Each slice was relaxed and re-hydrated, before histology imaging was performed using a 5x objective with 1.1$\mu$m resolution. Examples of the block face and slice images is displayed in Figures~\labelcref{fig:original_lores_images,fig:original_hires_images}, respectively.
		
		\begin{figure}[htbp]
		  \centering
		  \subfigure[][]{\includegraphics[width=0.8\pagewidth]{Ch6/Figs/LoRes_rgb_downsamples_1_0582}}
		  \subfigure[][]{\includegraphics[width=0.8\pagewidth]{Ch6/Figs/LoRes_rgb_downsamples_8_0582}}
		  \caption{Block face images of slice 582 of Rat 28. The original image is shown in \textbf{(a)}, with \textbf{(b)} Gaussian smoothed and downsampled by a factor of 8 in each dimension.}
		  \label{fig:original_lores_images}
		\end{figure}
    
    \begin{figure}[htbp]
      \centering
      \subfigure[][]{\includegraphics[width=0.8\pagewidth]{Ch6/Figs/HiRes_downsamples_8_0582}}
      \subfigure[][]{\includegraphics[width=0.8\pagewidth]{Ch6/Figs/HiRes_downsamples_64_0582}}
      \caption{Slice images of slice 582. \textbf{(a)} is Gaussian smoothed and downsampled by a factor of 8, and \textbf{(b)} by 64. The slice must be reflected and rotated in order to align with the block face image in Figure~\ref{fig:original_lores_images}.}
      \label{fig:original_hires_images}
    \end{figure}
	
  % subsection image_acquisition (end)

  \subsection{Image Curation} % (fold)
  \label{sub:image_curation}
    The images provided by Burton et al. yield unprecedented detail and quality. Although every possible step was taken during image acquisition, certain unavoidable experimental practicalities arose. A master subset of the images was selected, removing any slices with unacceptable damage such as that found in Figure~\ref{fig:damaged_slice}. Wherever a slice or group of slices was missing or removed, the acceptable adjacent slices were repeated symmetrically to fill the gap, in order to preserve the macroscopic geometry of the tissue. In the rare case where two images of the same slice existed, both slices were examined and the higher quality version was selected.
    
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=.8\textwidth]{Ch6/Figs/damaged_slice}
      \caption{A damaged slice close to the left extremity of the heart. The tissue is severely damaged and folded in place. There is also a large bubble trapped between the two imaging slides.}
      \label{fig:damaged_slice}
    \end{figure}
    
  % subsection image_curation (end)
  
  \subsection{Image Preparation} % (fold)
  \label{sub:image_preparation}
  	The digital camera used to obtain the images created files with four channels: red, green, blue and alpha. Since transparency is meaningless in the context of a photograph, the alpha channel was uniformly black. Unfortunately, the implementation of the RGBA BMP reader in ITK labels the channels incorrectly. To correct for this, channels were explicitly permuted and the redundant alpha channel removed.
  
    On occasion, part way through image acquisition, the block face camera would be moved relative to the surface of the wax block. All images acquired from then on had to be translated and rotated to compensate for this movement. At each perturbation, the two slices between which the camera had moved were registered in order to calculate the corrective transform, which was then applied to all subsequent slices. Figure~\ref{fig:LoRes_cross_sections} depicts the results of these corrections, and the isosurface of the corrected segmented volume are shown from 6 sides in Figures~\labelcref{fig:LoRes_positive_x,fig:LoRes_negative_x,fig:LoRes_positive_y,fig:LoRes_negative_y,fig:LoRes_positive_z,fig:LoRes_negative_z}. The isosurface was generated from a threshold segmentation of the intensity magnitude of the volume. A dense cloud of wax bubbles and other small artefacts obscured the main surface of the heart, and so a binary shape opening filter was applied to remove all but the largest connected region from the segmentation before the contour was extracted.
    
    % lores cross sections
    \begin{sidewaysfigure}[htbp]
      \centering
      \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/LoRes_without_adjustments_0_235}}
      \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/LoRes_without_adjustments_1_287}}
      \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/LoRes_0_235}\label{subfig:LoRes_adjusted_long_cross_section}}
      \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/LoRes_1_287}}
      \caption{Central cross-sections of the cropped block-face volume. \textbf{(a)} and \textbf{(b)} show the volume before adjustment, where a large camera displacement is apparent approximately a quarter of the way from the bottom of the image. Several thin stripes are visible further up, where the occasional single image has been displaced. The volume is fully aligned in \textbf{(c)} and \textbf{(d)}, with striations visible due to discrete changes in the positioning and intensity of illumination. These changes will propagate to the final registration result.}
      \label{fig:LoRes_cross_sections}
    \end{sidewaysfigure}
    
    % lores contours
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_positive_x}
      \caption{A contour of the adjusted block face volume, viewed along the positive x direction. The round surface of the heart apex is clearly visible to the right. Oddly shaped protrusions in the top third of slices are due to gradually brightening reflection from the suface of the wax.}
      \label{fig:LoRes_positive_x}
    \end{sidewaysfigure}
    
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_negative_x}
      \caption{The block face contour viewed along the negative x direction. The more complex surface of the valve and vascular machinery at the base of the heart is visible to the right.}
      \label{fig:LoRes_negative_x}
    \end{sidewaysfigure}
    
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_positive_y}
      \caption{The block face contour viewed along the positive y direction. The bulge of an epicardial vessel at the bottom right hand side is clearly visible (it is also faintly visible towards the bottom left of Figure~\ref{fig:LoRes_negative_x}). The discrete change in illumination from Figure~\ref{subfig:LoRes_adjusted_long_cross_section} manifests as an apparent increase in surface size approximately a third of the height from the bottom.}
      \label{fig:LoRes_positive_y}
    \end{sidewaysfigure}
    
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_negative_y}
      \caption{The block face contour viewed along the negative y direction.}
      \label{fig:LoRes_negative_y}
    \end{sidewaysfigure}
    
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_positive_z}
      \caption{The block face contour viewed along the positive z direction. The detail and composition of the images is clearly visible from this angle. Note the protruding epicardial vessel in the top left. The surface of the first third of slices near the bottom left looks eroded, in a region where the threshold intensity values have failed to pick up the tissue boundary faithfully.}
      \label{fig:LoRes_positive_z}
    \end{sidewaysfigure}
    
    \begin{sidewaysfigure}[htbp]
      \centering
      \includegraphics[width=\textheight]{Ch6/Figs/Rat28/contours/LoRes_negative_z}
      \caption{The block face contour viewed along the negative z direction. Bright reflection obscures much of the tissue surface from this angle, and the accurate registration of these top slices will prove impossible.}
      \label{fig:LoRes_negative_z}
    \end{sidewaysfigure}
    
	As is evident from Figures~\labelcref{fig:original_lores_images,fig:original_hires_images} for one slice, the vast majority of slices had been flipped over between sectioning from the block surface and being photographed. Slice images were therefore reflected across one axis in order to restore geometric parity with the associated block face image.
	
	 Several sets of downsamples of varying factors were generated, the lowest of which were used for debugging and testing, working up in detail, size and computational expense as the techniques were perfected. Before downsampling, a Gaussian smoothing was applied in each case, with sigma equal to the new larger pixel spacing. In this way, all original pixels in the region of a large downsampled pixel contribute to its final value, and aliasing noise problems associated with frthe Nyquist frequency are avoided. This results in a smoother and more accurate cost function. Figures~\labelcref{fig:original_lores_images,fig:original_hires_images} juxtapose the full images with various levels of downsampling.
	 
	 When registering two images, it is important that they are of comparable resolution, in order to minimise processing time and to ensure the smoothest possible cost function. In Figure~\ref{fig:downsample_zooms}, the effects of the downsampling can be seen more clearly. Individual cell nuclei are resolved at the highest resolution of slice image, but the maximum resolution block face images are of much lower detail. Clearly, the original slice images, with 1.1$\mu$m pixel spacings, are needlessly detailed compared to their block face counterparts, with a mere 26.6$\mu$m. As is discussed in Section~\ref{ssub:multiresolution_registration}, it is therefore appropriate to register slice images at a factor of 8 times more downsampled than the block face images.
    
	%  Lo/HiRes zooms
    \begin{sidewaysfigure}[htbp]
      \centering
      \subfigure[][]{\includegraphics[width=0.39\pagewidth]{Ch6/Figs/HiRes_downsamples_1_0582_zoom}}
      \subfigure[][]{\includegraphics[width=0.39\pagewidth]{Ch6/Figs/HiRes_downsamples_8_0582_zoom}}
      \subfigure[][]{\includegraphics[width=0.39\pagewidth]{Ch6/Figs/HiRes_downsamples_64_0582_zoom}}
      \subfigure[][]{\includegraphics[width=0.39\pagewidth]{Ch6/Figs/LoRes_rgb_downsamples_1_0582_zoom}}
      \subfigure[][]{\includegraphics[width=0.39\pagewidth]{Ch6/Figs/LoRes_rgb_downsamples_8_0582_zoom}}
      \caption{An epicardial vessel in slice 582 of Rat 28, in both the slice and the block face images. \textbf{(a)}, \textbf{(b)} and \textbf{(c)} show the slice original, 8x and 64x downsampled, while \textbf{(d)} and \textbf{(e)} show the block face original and 8x downsampled. The fibres parallel to the internal wall at the bottom of \textbf{(a)} are angled such that they reflect the illumination strongly at the top right of \textbf{(d)}, and are in much sharper contrast to the black wax than the rest of the tissue. Indeed, they are in much sharper contrast to the other tissue than the other tissue is to the non-tissue.}
      \label{fig:downsample_zooms}
    \end{sidewaysfigure}
  % subsection image_preparation_and_curation (end)
  
  \subsection{Initialisation} % (fold)
  \label{sub:initialisation}
    The optimisation algorithms used in registration do not assure convergence to the global minimum and are thus sensitive to initialisation and to the presence of local minima in the cost function. A reasonable initialisation is necessary for robust and accurate registration.
	
		\subsubsection{Geometric Initialisation} % (fold)
		\label{ssub:geometric_initialisation}
			The block face images are already coherent from their acquisition. White space under the microscope surrounding the slices had already been cropped, such that each slice sat approximately centrally within the bounds of its image. Having been reflected across the x-axis, an anticlockwise rotation of $90\,^{\circ}$ oriented most slices approximately with the block face, as is seen from Figures~\labelcref{fig:original_lores_images,fig:original_hires_images}. A small set of slices required $180\,^{\circ}$ rotations. Slice images were then initialised to their common centre to form a volume. The initial translation and pixel spacing of the block face volume was then manually tuned to overlap maximally with the slice volume. As is exhibited in Section~\ref{sec:results}, this naïve geometric initialisation provides an adequate starting point.
		% subsubsection geometric_initialisation (end)
	
		\subsubsection{PCA Initialisation} % (fold)
		\label{ssub:pca_initialisation}
			Although geometric initialisation provided a reasonable starting point for most slices, this was purely a consequence of how the experimentalist had manually obtained and cropped the original images. A more sophisticated method might make use of the information in the image. If the pixels containing tissue could be identified, the centres of mass and principal components of each pair of images can be aligned to provide a close initial matching.
		
		  Various segmentation methods were tested in an effort to identify tissue reliably in both sets of images. Because the block face volume was already coherent, volume-wise refinements and filters could be applied, whilst only 2D segementation techniques could be considered for the slice images.
			
			After applying any image preprocessing, such as a gradient magnitude or Hessian filter, many segmentation methods, such as opening and closing or level sets, are designed to refine the edges or surfaces of an approximate segmentation. Yet here it is to be noted that only the segmentation's moments are of consequence, in particular the centre of mass and the variance matrix. It is therefore unnecessary for the segmentation to overlap closely with the tissue at a small scale, only that the global distribution of tissue be represented precisely. That being said, methods to remove macroscopic artefacts, such as connected component filtering and selection proved beneficial in most contexts.
			
		  There is no facility to align the principal components of two images in ITK, only to align their centres of mass. The class itk::CenteredTransformPCAInitializer was implemented to encapsulate the details of this process. The results of applying this class compared to the simple geometric initialisation are shown in Figure~\ref{fig:582_pca}, and the segmentations upon which they are based are shown in Figure~\ref{fig:582_segmentation}.
		
	    It is somewhat clear from Figure~\ref{fig:LoRes_cross_sections} that the broad range of tissue colours and intensities in the block face volume overlap significantly with the colours and intensities of non-tissue. In Figures~\labelcref{fig:582_segmentation,fig:582_pca}, the threshold segmentation values were optimised for these particular slices as a proof of concept, but this slice was chosen as one of the best examples of the technique. Issues such as wax bubbles, the bright blob at the top of the block face volume, optical transmission from layers below, and differential brightness from differing fibre directions or anatomical features plagued efforts to segment the images, and in fact went on to plague registration. Even if a segmentation method could yield reasonable results for every slice in the dataset, it is impractical to tune parameters manually for each slice, and there would certainly not be a single parameter set suitable for every slice in the volume. For these reasons, the PCA method could not be used to improve robustly upon a simple geometric initialisation of the high-resolution slices seen in Figure~\ref{fig:geometric_initialisation}.
    
	  \begin{figure}[htbp]
	    \centering
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/LoRes_562}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/LoRes_segmentation_562}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/HiRes_562}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/HiRes_segmentation_562}}
      \caption{Originals and threshold segmentations of the block face and slice images of slice 582.}
	    \label{fig:582_segmentation}
	  \end{figure}
    
	  \begin{figure}[htbp]
	    \centering
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/geometric_redblue}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/geometric_segmentation_redblue}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/pca_redblue}}
      \subfigure[][]{\includegraphics[width=0.4\pagewidth]{Ch6/Figs/pca/pca_segmentation_redblue}}
      \caption{Intensity superpositions of block face (red channel) and slice (blue channel). The original images are used \textbf{(a)} and \textbf{(c)}, while the segmentations are shown in \textbf{(b)} and \textbf{(d)}. \textbf{(a)} and \textbf{(b)} show geometric initialisation, and \textbf{(c)} and \textbf{(d)} PCA initialisation. It is clear that PCA provides a much closer match from which the registration algorithm can begin.}
      \label{fig:582_pca}
    \end{figure}
    
		% subsubsection pca_initialisation (end)
  % subsection initialisation (end)
  
	\subsection{Registration Algorithm} % (fold)
  \label{sub:registration_algorithm}
    Each main aspect of the registration method is outlined in this section. A well-founded registration algorithm must embody three traits: numerically, it must converge reliably to the global minimum; computationally, it must be efficient so as to be tractable; and physically, it must correspond to the process that it was designed to correct for. It is through the lens of these three benchmarks that we examine the following components.
    
    \subsubsection{Transforms} % (fold)
    \label{ssub:transforms}
			The sectioning of the slices introduces 2-D, slice-specific deformation and in some cases damage. The subsequent relaxing and rehydration of each slice causes further deformation. A large proportion of this deformation will be of similarity or affine form. By first registering the simplest of transforms with the lowest dimensional parameter space, and then incrementally relaxing transformational constraint by increasing the number of parameters, we can provide the best possible starting point in each higher dimensional parameter space.
			
      Transforms were optimised in the following order, the final result of each initialising its successor: a centered rigid 2D transform - a rotation about an arbitrary centre followed by a translation; a centred similarity transform - as before but with a scaling factor; and a centred affine transform - an affine transformation around an arbitrary centre followed by a translation. For all transforms, the centre of rotation was exposed for optimisation as metric parameters. Finally, a coarse grid and subsequent fine grid bspline deformable transform was tested, but found to be unstable.
    % subsubsection transforms (end)
    
    \subsubsection{Metrics} % (fold)
    \label{ssub:metrics}
      Mutual Information (MI) is usually considered to be most effective when registering images from different modalities. However, after a plethora of parameterisations and configurations was explored based on this metric with little success, incrementally simpler and simpler metrics were tested. Each demanded more image preconditioning and tuning, but yielded monotonically closer and more consistent registrations, with a larger capture range, and required fewer iterations to converge. First, a normalised correlation was employed, with the simplest mean squares difference algorithm proving most suitable. It would appear that the simpler the intensity relationship, the smoother the cost landscape, with fewer local minima.
    % subsubsection metrics (end)
  
    \subsubsection{Optimisation} % (fold)
    \label{ssub:optimisation}
      Gradient Descent (GD) and Regular Step Gradient Descent (RSGD) optimisers have been applied. RSGD terminates before the maximum number of iterations has passed, and so in simple cases it is computationally more efficient. In most scenarios, however, the GD optimiser often proves more robust. In both cases, a choice to maximise or minimise the cost function must be chosen, the latter being dependent on both the choice of metric and the preconditioning of the image intensity ranges.

      The optimisation space, as dictated by the transform, must be scaled along each dimension to correct for discrepant effects per unit change of each parameter. For example, a translation of one micron at the epicardium might result from a rotation of just $10^{-5}$ radians about the centre of the slice. This makes the metric space more isotropic and reduces the eccentricity of cost function basins, allowing the optimisation algorithm to fall more directly toward minima.
    % subsubsection optimisation (end)
	% subsection registration_algorithm (end)
    
  \subsection{Software Architecture} % (fold)
  \label{sub:software_architecture}
		From early on, the requirements of the problem diversified, and a range of related tools were built. Common patterns and functionality needed to be extracted and isolated. This prevented duplication and the potential for bugs and inconsistencies, and lead to more readable and manageable code. Because the final result was unknown, it was often extremely difficult to know whether the code was operating correctly. Bugs or errors in calculation were not usually apparent, and proved very difficult to find. We outline the main problems encountered during the development process, along with the solutions crafted to isolate and overcome them.
		
		\subsubsection{Languages and Frameworks} % (fold)
		\label{ssub:languages_and_frameworks}
      All file handling and networking algorithms were written in Ruby. Imaging algorithms were written in C++ or, in some simple cases, Python, using the venerable ITK library. C++ executables were compiled using the cross-platform build system CMake. YAML was used as a declarative language for configuration files, providing a syntax that is easily human readable and curatable, yet machine parsable. Source code management and code deployment was implemented in Git, and the project is freely available at \url{http://github.com/mattgibb/registration} under an MIT license.
		% subsubsection languages_and_frameworks (end)
		
    \subsubsection{Stacks} % (fold)
    \label{ssub:stacks}
      Each block image must be paired with its equivalent slice image, and blank images must be interpolated where images are missing. Slices must be transformed independently and by a range of transform types. Resampler spacings must be set according to the original image spacings and the downsample ratios. Binary masks must be generated for each image, so that metrics will only take pixel intensities into account from inside the boundaries of the original untransformed images. A stack volume must be reconstructed from the transformed, resampled slices. A minimum percentage overlap is required for many metrics to function, and for small slice images close to the apex of the heart, block mask areas must be cropped until this constraint is satisfied.
	  	
      A heirarchy of Stack classes has been developed - along with associated builder classes, IO helpers and transform converters - to encapsulate the solutions to all of these problems. A Stack represents the 3D composition of a set of 2D slices. It handles ROI selection, generic transform storage, image and mask resampling and generation (both for 2D slices and for the 3D volume) and various error handling strategies. An MRI class is also available to solve the complementary problem of extracting arbitrarily oriented slices from a 3D image. However, for these specific datasets the block face images are intrinsically registered to the histological samples.
    % subsubsection stacks (end)
    
    \subsubsection{Multiresolution Registration} % (fold)
    \label{ssub:multiresolution_registration}
      SECTION ON MULTIRESOLUTION, BOTH IN PLANE AND WITH IMAGE LISTS. TALK ABOUT REPRESENTATIVE SETS OF SLICES 100-110 + 200-210 + 300-310 ETC. TALK ABOUT TRACTABILITY WITH IMAGE SIZE AND TIME FOR REGISTRATION, AND HOW EACH ALGORITHM WAS SPLIT UP INTO INDIVIDUAL SLICES
      
	  The full-resolution histology dataset can measure 2TB
	  
      Motivate multires: state figures on total size of dataset, and on total times and memory to run 1 registration on a laptop and on a supercomputer. Talk about high dimensionality of parameter space, and the need for rapid feedback if the right parameters are to be found in any reasonable time.
    
      There are 2 ways to achieve this: in-plane downsampling and out-of-plane slice selection. Downsampling and Gaussian smoothing not only reduces time, but smooths the cost function and can lead to more robust registration results. In multiresolution registration, the resulting transforms can then be used to initialise a more accurate but more fragile registration at a higher resolution.
    
		
    % subsubsection multiresolution_registration (end)
    
    \subsubsection{Builders} % (fold)
    \label{ssub:builders}
      A minimal registration pipeline is composed of several generic actors, including a metric, an optimiser, a transform, and an interpolator. The details of which types of actors are optimal and how they should interact are peculiar to the registration problem at hand. Furthermore, the specific type of each component often requires unique configuration beyond the generic interface of its family, and the choice of image preprocessing is dependent on the choice of metric. Once several types must be chosen from and configured, even for just one component, an ad hoc procedural approach quickly became unwieldy. These two requirements colluded combinatorially to demand a great deal of testing, tailoring and configuration in order to achieve registrations of high quality. More often than not, modifications would degrade the registration.
			
      At the pipeline level, we developed a heirarchy of frameworks employing the Builder pattern (\cite{Gamma1995}), which abstracts away the heavy lifting of wiring up the various components together.  At the component level, a conflation of the Abstract Factory and the Strategy patterns (\cite{Gamma1995}), together with a configuration system using the human-friendly YAML markup language, serves not only to decouple the actors' representations from the minutiae of their construction, but to move these volatile decisions from compile-time to runtime. These tools vastly reduce the cost of experimentation and testing. With all the variables clearly grouped together, with no need to recompile the toolchain or pore through source code to find if and where one can make a change, the feedback from results is faster and less error prone.
      
			The StackAligner class encapsulates the registration process, for tools employing affine or b-spline deformable transforms, across the whole heart or in a region of interest. At least two sets of stack configurations were required, for the block face and slice stacks, across a great many registration and reconstruction tools. This logic was pulled into a StackBuilder class tree, rooted from an untemplated StackBuilderBase class to prevent template infection across the codebase.
    % subsubsection builders (end)
		
		\subsubsection{Events, Checkpointing and IO} % (fold)
		\label{ssub:events_checkpointing_and_io}
			It is necessary to save intermediate information about the progress of the registration, for parameter tuning and analysis. ITK exposes this functionality through the Command Observer pattern (see \cite{Gamma1995})). Any ITK object can publish events, and other objects may subscribe to those events. An object whose purpose is to subscribe to an event and perform an action when that event is triggered is called a Command Observer. Figure~\ref{fig:command_heirarchy} shows the class tree developed to display and record the required information.
			
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=\pagewidth]{Ch6/Figs/command_heirarchy}
      \caption{Command Observer heirarchy to output various types of information when specific events are triggered.}
      \label{fig:command_heirarchy}
    \end{figure}
		
      At any stage during the registration process, the vector of transforms held by a given Stack can be persisted to a series of files with a single function call. Just as easily, a new Stack can be initialised with a set of transforms on storage. This machinery facilitates greater process granularity in three dimensions: in the sequence of transforms to be optimised, in the increasing image resolutions to be registered, and spatially in the pairs of slices within the Stack. In the first case, a user can tune one registration stage until they are happy that it is optimal, and then use the results as a starting point for all subsequent runs of the next stage. In the second case, approximate registrations can be performed with images at lower resolutions, which can then initialise registrations at higher resolutions with different images. In the third case, the result from separate jobs for each slice pair using images of a scalar floating point pixel type or a segmentation image type can be aggregated and used to reconstruct a colour volume, perhaps at a different resolution. This division of workload and memory is of particular importance when organising jobs on clusters and shared memory machines.
			
			Even aside from process granularity, working with transforms is vastly superior to working directly with the images. Composing transforms rather than repeatedly resampling prevents a loss of image quality due to rasterisation in differing coordinate systems. Advanced composition of transforms makes possible registration refinement, either in regions of interest, or with the diffusion smoothing techniques discussed in Chapter~\ref{cha:diffusion_smoothing_registration_of_high_resolution_rat_histology}.
          
          Several other aspects of the architecture are not discussed here, including configuration, file management, testing, as well as the opportunities and challenges posed by high performance computing.
		% subsubsection events_checkpointing_and_io (end)
		
  % subsection software_architecture (end)
  
    \subsection{Diagnostics and Parameter Tuning} % (fold)
    \label{sub:diagnostics}
      For almost a year and a half, it was very difficult to see why registration was failing to yield robustly accurate results. The output of raw parameters was somewhat elucidating, but only for obvious issues such as parameter scaling and step length, where almost zero change in some or all parameters signalled what to adjust. The space of possible parameters was enormous, and the computing time before feedback significant. With visual representation of nothing but the final result, divining which parameters to change and how was perhaps analogous to deciding how each player in a sports team could improve given only the final scores.
      
      Armed with the intermediate transforms and metric values discussed in Section~\ref{ssub:events_checkpointing_and_io}, the causes of the suboptimal registration results were immediately apparent. The progression of metric values for all slices could be plotted in graphs like those in Figures~\labelcref{fig:rigid_metric_values,fig:similarity_metric_values,fig:affine_metric_values,fig:affine_metric_value_differences}. Progress volumes of a particular slice could be constructed as seen in Figures~\labelcref{fig:progress_cross_sections,fig:progress_contour}.
			
			The regular step gradient descent optimiser is parameterised with four values: two behavioural values (maximum step length and relaxation factor), and two cutoff values (minimum step length and gradient magnitude tolerance). Bad behavioural values manifest in static or `zigzagging' unstable progress volumes and metric values, whilst premature or overcautious cutoff values yield either no region or a needlessly large region of equilibrium at the end. Bad parameter scaling is not evident solely from the intermediate metric values, which can still remain smoothly increasing with a quasi-equilibrated final section. However, the progress volume will appear restricted in one or more dimension. For example, the slice may rotate freely, but remain at a fixed translation, despite an obvious translational cost gradient.
			
			Not all symptoms could be diagnosed. In rare cases, the metric value would gradually and consistently worsen, and it was unclear why this was happening. Perhaps an oddly shaped cost basin or saddle point was to blame, deepening steeply along one dimension and shallowly along a perpendicular one.
			
      Interestingly, before an upgrade to ITKv4, the registration algorithm would often not optimise, but rather diffuse in a seemingly random way between metric values. Even though the upgrade should not have affected the registration outcome, but just the speed of the code, results were suddenly much better.
      
    % subsection diagnostics (end)
% section methods (end)
   
\section{Results} % (fold)
\label{sec:results}
	Intro: list each paragraph.
	The work leading up to this chapter is composed of a great many dead ends and failed experiments, and the result presented here is merely the best outcome. Details of computation times are followed by the plotting of intermediate and final metric values. The progress of a single representative slice is scrutinised, ending with cross-sections and contours of the registered histological volumes after each successive registration.
	
	Para on computing times.
	Give times to run 1500 iterations on supercomputer. To begin with, lower resolution images were used to approximate parameters in reasonable time, but all registrations shown here were performed with the full resolution block face images and 8x downsampled slice images. On a MacBook Pro with a 2.4GHz Intel Quad Core i7 processor, registering the original block face image to an 8x downsampled slice image took approximately 0.25 seconds per iteration. For the 1500 iterations required for rigid registration, and for 900 slices, this extrapolates to 93 hours total run time. When jobs were distributed on the cluster, 12 parallel registrations could be run concurrently in times of low demand. The total registration time was reduced from 93 hours to just below 7 hours.
	
	Para on intermediate values.
	By far most of the registration is done in the first rigid step. Didn't work for lots of reasons, tried PCA, ITKv3 bug, different metrics, optimisers, normalising images etc. loads of figures.
	
	Para on final values.
	
	Para on single slice.
	
	Para on cross-sections.
	
	Para on contours.
	
  \begin{sidewaysfigure}[htbp]
    \centering
    \includegraphics[width=\textheight]{Ch6/Figs/diagnostics/rigid_metric_values}
    \caption{Intermediate metric values for all slices during rigid registration. The graph is viewed from below to see all values clearly. Nearly all curves increase smoothly and monotonically, before reaching a distinct flat maximum. After around slice 600, where the blob-shaped artefact appears, the final metric values decrease almost linearly as the intensity of the blob increases. Slices in the region of 400-600 start from a much lower metric value, and take up to 1500 iterations to maximise. This was due to their geometric initialisations being much further from their final optimal position. Diagnostics were of critical importance here, not least to see whether all slices had reached their optimum position.}
    \label{fig:rigid_metric_values}
  \end{sidewaysfigure}
      
  \begin{sidewaysfigure}[htbp]
    \centering
    \includegraphics[width=\textheight]{Ch6/Figs/diagnostics/similarity_metric_values}
    \caption{}
    \label{fig:similarity_metric_values}
  \end{sidewaysfigure}
      
  \begin{sidewaysfigure}[htbp]
    \centering
    \includegraphics[width=\textheight]{Ch6/Figs/diagnostics/affine_metric_values}
    \caption{}
    \label{fig:affine_metric_values}
  \end{sidewaysfigure}
      
  \begin{sidewaysfigure}[htbp]
    \centering
    \includegraphics[width=\textheight]{Ch6/Figs/diagnostics/affine_metric_value_differences}
    \caption{}
    \label{fig:affine_metric_value_differences}
  \end{sidewaysfigure}
      
  \begin{sidewaysfigure}[htbp]
    \centering
    \includegraphics[width=\textheight]{Ch6/Figs/diagnostics/initial_and_final_values_comparison}
    \caption{Each successive registration increases correlation, but it is clear that the vast majority of improvement comes from the rigid registration. PERHAPS MOVE THE FOLLOWING TEXT SOMEWHERE ELSE: slices from 380 to 600 were photographed at a larger angle from that of their block-face images, and this is reflected in a sharply reduced initial correlation value. From Slice 600 onwards, the blob precludes successful registration and both initial and final correlation values decline.}
    \label{fig:initial_and_final_values_comparison}
  \end{sidewaysfigure}
      
  \begin{figure}[htbp]
    \centering
    \subfigure[][]{\includegraphics[height=0.3\textheight]{Ch6/Figs/diagnostics/fixed_progress_slice_0562_1_287.pdf}}
    \subfigure[][]{\includegraphics[height=0.3\textheight]{Ch6/Figs/diagnostics/moving_progress_slice_0562_1_287.pdf}}
    \subfigure[][]{\includegraphics[height=0.3\textheight]{Ch6/Figs/diagnostics/fixed_progress_slice_0562_0_235.pdf}}
    \subfigure[][]{\includegraphics[height=0.3\textheight]{Ch6/Figs/diagnostics/moving_progress_slice_0562_0_235.pdf}}
    \caption{Progress volume of 1500 iterations of slice 0562}
    \label{fig:progress_cross_sections}
  \end{figure}
      
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=\pagewidth]{Ch6/Figs/diagnostics/0562_contour.png}
    \caption{Quick rotation at the start, then flatter, slower translation...finally reaches a stationary minimum in the last iterations.}
    \label{fig:progress_contour}
  \end{figure}
      
  \begin{figure}[p]
    \centering
    \subfigure[][]{\includegraphics[width=0.9\pagewidth]{Ch6/Figs/diagnostics/0562_correlation}}
    \subfigure[][]{\includegraphics[width=0.9\pagewidth]{Ch6/Figs/diagnostics/0562_delta_correlation}}
    \caption{What a nice figure!}
    \label{fig:0562_correlation}
  \end{figure}
	
	% initialisation figure
	\begin{sidewaysfigure}[htbp]
	  \centering
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/geometric_0_235}}
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/geometric_1_287}}
	  \caption{}
	  \label{fig:geometric_initialisation}
	\end{sidewaysfigure}

	% x slices
	\begin{figure}[htbp]
	  \centering
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/rigid_0_235}}
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/size_0_235}}
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/affine_0_235}}
	  \caption{Talk about how discontinuities in intensity between slices in the LoRes cutthrough fig are mirrored in the registration}
	  \label{fig:hires_0_235}
	\end{figure}

	% y slices
	\begin{figure}[htbp]
	  \centering
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/rigid_1_287}}
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/size_1_287}}
	  \subfigure[][]{\includegraphics[height=0.31\textheight]{Ch6/Figs/affine_1_287}}
	  \caption{What a nice figure!}
	  \label{fig:hires_1_287}
	\end{figure}

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	blah blah

	% geometric contours
	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_x_geometric}
	  \caption{Contour details: threshold segmentation with limits:0 to 240, used original slice images that were Gaussian smoothed by a kernel of std dev 64, because the detail from a simple threshold on nonsmoothed images generated egregiously convoluted surfaces. Because this smoothing only operates within the plane of the slices, individual displacements between edges of adjacent slices is still clearly visible. After segmentation, a label map filter was applied to remove all but the largest connected component. This went some way to removing bubbles and other artefacts obscuring the surface of the heart. y-dimension of geometry bounding box is extended from 575 to 700 to encompass the increased spread of the slices.}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_negative_x_geometric}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_y_geometric}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_z_geometric}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	% rigid contours
	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_x_rigid}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_negative_x_rigid}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_y_rigid}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_z_rigid}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	% size contours
	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_x_size}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_negative_x_size}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_y_size}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_z_size}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	% affine contours
	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_x_affine}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_negative_x_affine}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_y_affine}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}

	\begin{sidewaysfigure}[p]
	  \centering
	  \includegraphics[width=0.9\textheight]{Ch7/Figs/Rat28/contours/whole_positive_z_affine}
	  \caption{}
	  \label{fig:image1.png}
	\end{sidewaysfigure}
	
% section results (end)

\section{Discussion} % (fold)
\label{sec:discussion}

\textit{PROGRESS FROM CONFIRMATION REPORT 
A full-heart registration pipeline has been developed and downsampled histological volumes generated. An initial manual alignment is followed by rigid and similarity transforms. The quality of the registrations are quite poor at present, and the task at hand is to fine-tune the various parameters that constrain the process: parameter space preconditioning, maximum iterations, maximum and minimum step lengths, number of spatial samples and metric-specific parameters.
END PROGRESS FROM CONFIRMATION REPORT
}
    We have constructed a comprehensive, generic and flexible pipeline to register histological slices to block face images, that can be configured to generate rapid results on the broadest spectrum of computational facilities, from laptop, to cluster, to shared memory supercomputer.
    
    Talk about ad hoc meta-optimisation of registration parameters, could be more formalised but a great deal more effort and prone to error (e.g. mean final metric values of all slices might decrease, but end result may suck)
    
    The method for optimising registration parameters is a crude and intuitive version of the optimisation algorithms applied to the image registrations. Not easily possible to calculate gradient of metric in parameter space, but can perturb coordinates along basis axes e.g. parameter scaling, choice of metric or optimiser, gradient descent learning rate, RSGD relaxation factor, whether to normalise images etc. 2 approaches: could split the space into two groups of `preferred' axes, and secondary axes, then perform an (exhaustive?) prototype search in the preferred subspace, and for each preferred coordinate perform an iterative optimisation in the secondary space. Alternatively, just perform iterative stochastic search in the whole space.
    
    ?NEEDS DEVELOPMENT? Some params like choice of metric have different associated parameter spaces e.g. learning rate vs relaxation factor, and also are likely to lead to widely different optimal spaces along other axes e.g. parameter scaling.
    
    Problems about things like histogram matching, Mutual info: for histogram matching there is no monotonic mapping between the intensity in the lores and that of the hires, with tissue /non tissue. With Mutual info, doesn't need to be monotonic, but there isn't even a one-to-one mapping i.e. many regions of tissue in lores occupy the same intensity range as non-tissue.
    
    Conclude that experimental acquisition techniques have advanced since Rat28 was acquired, and some of the image processing techniques exposed here will perform much better with even higher quality and more homogeneous data.
    
    Dicuss why b-splines didn't work.
% section discussion (end)
